{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gihad Abdelhamid\n",
    "# 20196899\n",
    "# MMA\n",
    "# W21\n",
    "# 869\n",
    "# 16-Aug-2020\n",
    "\n",
    "# Answer to Question 7, Part 7a\n",
    "#Load, clean, and preprocess the data as you find necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) 2a - Preprocess the data however you see fit. In code comments, describe what you did and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data from OJ.csv I am assuming that you have the file in the same directory as the py file\n",
    "df = pd.read_csv(\"OJ.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1070 entries, 0 to 1069\n",
      "Data columns (total 19 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Unnamed: 0      1070 non-null   int64  \n",
      " 1   Purchase        1070 non-null   object \n",
      " 2   WeekofPurchase  1070 non-null   int64  \n",
      " 3   StoreID         1070 non-null   int64  \n",
      " 4   PriceCH         1070 non-null   float64\n",
      " 5   PriceMM         1070 non-null   float64\n",
      " 6   DiscCH          1070 non-null   float64\n",
      " 7   DiscMM          1070 non-null   float64\n",
      " 8   SpecialCH       1070 non-null   int64  \n",
      " 9   SpecialMM       1070 non-null   int64  \n",
      " 10  LoyalCH         1070 non-null   float64\n",
      " 11  SalePriceMM     1070 non-null   float64\n",
      " 12  SalePriceCH     1070 non-null   float64\n",
      " 13  PriceDiff       1070 non-null   float64\n",
      " 14  Store7          1070 non-null   object \n",
      " 15  PctDiscMM       1070 non-null   float64\n",
      " 16  PctDiscCH       1070 non-null   float64\n",
      " 17  ListPriceDiff   1070 non-null   float64\n",
      " 18  STORE           1070 non-null   int64  \n",
      "dtypes: float64(11), int64(6), object(2)\n",
      "memory usage: 159.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check some data frame info\n",
    "df.info()\n",
    "\n",
    "# Create variables to identify the ID column and the target\n",
    "Id_col = 'Unnamed: 0'\n",
    "target_col = 'Purchase'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert some features into categories since they are not really numeric \n",
    "# and will result in inaccuracy issues if they are kept as numeric\n",
    "df['Purchase']=df['Purchase'].astype('category')\n",
    "df['StoreID']=df['StoreID'].astype('category')\n",
    "df['SpecialCH']=df['SpecialCH'].astype('category')\n",
    "df['SpecialMM']=df['SpecialMM'].astype('category')\n",
    "df['STORE']=df['STORE'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Store7 Yes/No into 1/0 flag\n",
    "df['Store7'] = df.Store7.apply(lambda x: 1 if x =='Yes' else 0)\n",
    "df['Store7']=df['Store7'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1070 entries, 0 to 1069\n",
      "Data columns (total 19 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   Unnamed: 0      1070 non-null   int64   \n",
      " 1   Purchase        1070 non-null   category\n",
      " 2   WeekofPurchase  1070 non-null   int64   \n",
      " 3   StoreID         1070 non-null   category\n",
      " 4   PriceCH         1070 non-null   float64 \n",
      " 5   PriceMM         1070 non-null   float64 \n",
      " 6   DiscCH          1070 non-null   float64 \n",
      " 7   DiscMM          1070 non-null   float64 \n",
      " 8   SpecialCH       1070 non-null   category\n",
      " 9   SpecialMM       1070 non-null   category\n",
      " 10  LoyalCH         1070 non-null   float64 \n",
      " 11  SalePriceMM     1070 non-null   float64 \n",
      " 12  SalePriceCH     1070 non-null   float64 \n",
      " 13  PriceDiff       1070 non-null   float64 \n",
      " 14  Store7          1070 non-null   category\n",
      " 15  PctDiscMM       1070 non-null   float64 \n",
      " 16  PctDiscCH       1070 non-null   float64 \n",
      " 17  ListPriceDiff   1070 non-null   float64 \n",
      " 18  STORE           1070 non-null   category\n",
      "dtypes: category(6), float64(11), int64(2)\n",
      "memory usage: 115.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Check some data frame info after converting to categorical\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) 2.b Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into 80/20 so that we can do cross validation after training the model on real data, \n",
    "# which is the remaining 20%\n",
    "\n",
    "# I used the train_test_split function to create 4 data frames, training frames for the features and the target \n",
    "# and validation frames for the features and target\n",
    "\n",
    "# The test size parameter defines the split, in this case I used 0.2 since it's an 80/20 split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop([Id_col, target_col], axis=1)\n",
    "y = df[target_col]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1070 entries, 0 to 1069\n",
      "Data columns (total 17 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   WeekofPurchase  1070 non-null   int64   \n",
      " 1   StoreID         1070 non-null   category\n",
      " 2   PriceCH         1070 non-null   float64 \n",
      " 3   PriceMM         1070 non-null   float64 \n",
      " 4   DiscCH          1070 non-null   float64 \n",
      " 5   DiscMM          1070 non-null   float64 \n",
      " 6   SpecialCH       1070 non-null   category\n",
      " 7   SpecialMM       1070 non-null   category\n",
      " 8   LoyalCH         1070 non-null   float64 \n",
      " 9   SalePriceMM     1070 non-null   float64 \n",
      " 10  SalePriceCH     1070 non-null   float64 \n",
      " 11  PriceDiff       1070 non-null   float64 \n",
      " 12  Store7          1070 non-null   category\n",
      " 13  PctDiscMM       1070 non-null   float64 \n",
      " 14  PctDiscCH       1070 non-null   float64 \n",
      " 15  ListPriceDiff   1070 non-null   float64 \n",
      " 16  STORE           1070 non-null   category\n",
      "dtypes: category(5), float64(11), int64(1)\n",
      "memory usage: 106.3 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1070, 17)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WeekofPurchase</th>\n",
       "      <th>StoreID</th>\n",
       "      <th>PriceCH</th>\n",
       "      <th>PriceMM</th>\n",
       "      <th>DiscCH</th>\n",
       "      <th>DiscMM</th>\n",
       "      <th>SpecialCH</th>\n",
       "      <th>SpecialMM</th>\n",
       "      <th>LoyalCH</th>\n",
       "      <th>SalePriceMM</th>\n",
       "      <th>SalePriceCH</th>\n",
       "      <th>PriceDiff</th>\n",
       "      <th>Store7</th>\n",
       "      <th>PctDiscMM</th>\n",
       "      <th>PctDiscCH</th>\n",
       "      <th>ListPriceDiff</th>\n",
       "      <th>STORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.75</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091398</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>227</td>\n",
       "      <td>1</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>7</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.956535</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WeekofPurchase StoreID  PriceCH  PriceMM  DiscCH  DiscMM SpecialCH  \\\n",
       "0             237       1     1.75     1.99    0.00     0.0         0   \n",
       "1             239       1     1.75     1.99    0.00     0.3         0   \n",
       "2             245       1     1.86     2.09    0.17     0.0         0   \n",
       "3             227       1     1.69     1.69    0.00     0.0         0   \n",
       "4             228       7     1.69     1.69    0.00     0.0         0   \n",
       "\n",
       "  SpecialMM   LoyalCH  SalePriceMM  SalePriceCH  PriceDiff Store7  PctDiscMM  \\\n",
       "0         0  0.500000         1.99         1.75       0.24      0   0.000000   \n",
       "1         1  0.600000         1.69         1.75      -0.06      0   0.150754   \n",
       "2         0  0.680000         2.09         1.69       0.40      0   0.000000   \n",
       "3         0  0.400000         1.69         1.69       0.00      0   0.000000   \n",
       "4         0  0.956535         1.69         1.69       0.00      1   0.000000   \n",
       "\n",
       "   PctDiscCH  ListPriceDiff STORE  \n",
       "0   0.000000           0.24     1  \n",
       "1   0.000000           0.24     1  \n",
       "2   0.091398           0.23     1  \n",
       "3   0.000000           0.00     1  \n",
       "4   0.000000           0.00     0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 856 entries, 351 to 860\n",
      "Data columns (total 17 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   WeekofPurchase  856 non-null    int64   \n",
      " 1   StoreID         856 non-null    category\n",
      " 2   PriceCH         856 non-null    float64 \n",
      " 3   PriceMM         856 non-null    float64 \n",
      " 4   DiscCH          856 non-null    float64 \n",
      " 5   DiscMM          856 non-null    float64 \n",
      " 6   SpecialCH       856 non-null    category\n",
      " 7   SpecialMM       856 non-null    category\n",
      " 8   LoyalCH         856 non-null    float64 \n",
      " 9   SalePriceMM     856 non-null    float64 \n",
      " 10  SalePriceCH     856 non-null    float64 \n",
      " 11  PriceDiff       856 non-null    float64 \n",
      " 12  Store7          856 non-null    category\n",
      " 13  PctDiscMM       856 non-null    float64 \n",
      " 14  PctDiscCH       856 non-null    float64 \n",
      " 15  ListPriceDiff   856 non-null    float64 \n",
      " 16  STORE           856 non-null    category\n",
      "dtypes: category(5), float64(11), int64(1)\n",
      "memory usage: 91.8 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(856, 17)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WeekofPurchase</th>\n",
       "      <th>StoreID</th>\n",
       "      <th>PriceCH</th>\n",
       "      <th>PriceMM</th>\n",
       "      <th>DiscCH</th>\n",
       "      <th>DiscMM</th>\n",
       "      <th>SpecialCH</th>\n",
       "      <th>SpecialMM</th>\n",
       "      <th>LoyalCH</th>\n",
       "      <th>SalePriceMM</th>\n",
       "      <th>SalePriceCH</th>\n",
       "      <th>PriceDiff</th>\n",
       "      <th>Store7</th>\n",
       "      <th>PctDiscMM</th>\n",
       "      <th>PctDiscCH</th>\n",
       "      <th>ListPriceDiff</th>\n",
       "      <th>STORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>278</td>\n",
       "      <td>7</td>\n",
       "      <td>2.06</td>\n",
       "      <td>2.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.982408</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>236</td>\n",
       "      <td>2</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>1.99</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>259</td>\n",
       "      <td>7</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.868928</td>\n",
       "      <td>2.18</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>260</td>\n",
       "      <td>3</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011649</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>231</td>\n",
       "      <td>2</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.135607</td>\n",
       "      <td>1.69</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177515</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     WeekofPurchase StoreID  PriceCH  PriceMM  DiscCH  DiscMM SpecialCH  \\\n",
       "351             278       7     2.06     2.13     0.0     0.0         0   \n",
       "530             236       2     1.75     1.99     0.0     0.0         0   \n",
       "896             259       7     1.86     2.18     0.0     0.0         0   \n",
       "947             260       3     1.99     2.09     0.0     0.0         0   \n",
       "936             231       2     1.69     1.69     0.3     0.0         1   \n",
       "\n",
       "    SpecialMM   LoyalCH  SalePriceMM  SalePriceCH  PriceDiff Store7  \\\n",
       "351         0  0.982408         2.13         2.06       0.07      1   \n",
       "530         0  0.680000         1.99         1.75       0.24      0   \n",
       "896         0  0.868928         2.18         1.86       0.32      1   \n",
       "947         0  0.011649         2.09         1.99       0.10      0   \n",
       "936         0  0.135607         1.69         1.39       0.30      0   \n",
       "\n",
       "     PctDiscMM  PctDiscCH  ListPriceDiff STORE  \n",
       "351        0.0   0.000000           0.07     0  \n",
       "530        0.0   0.000000           0.24     2  \n",
       "896        0.0   0.000000           0.32     0  \n",
       "947        0.0   0.000000           0.10     3  \n",
       "936        0.0   0.177515           0.00     2  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the dataframes \n",
    "X.info()\n",
    "X.shape\n",
    "X.head()\n",
    "\n",
    "X_train.info()\n",
    "X_train.shape\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) 2.c Building 3 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop([Id_col, target_col], axis=1)\n",
    "y = df[target_col]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Naive Bayes algorithm and check the performance metrics\n",
    "# Naive Bayes doesn't have hyperparameters to tune\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb = gnb.fit(X_train, y_train)\n",
    "gnb\n",
    "\n",
    "y_pred_gnb = gnb.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[96, 34],\n",
       "       [22, 62]], dtype=int64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.81      0.74      0.77       130\n",
      "          MM       0.65      0.74      0.69        84\n",
      "\n",
      "    accuracy                           0.74       214\n",
      "   macro avg       0.73      0.74      0.73       214\n",
      "weighted avg       0.75      0.74      0.74       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Will create and print a confusion matrix to inspect the performance metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "confusion_matrix(y_val, y_pred_gnb)\n",
    "print(classification_report(y_val, y_pred_gnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.01, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[119,  11],\n",
       "       [ 34,  50]], dtype=int64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.78      0.92      0.84       130\n",
      "          MM       0.82      0.60      0.69        84\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.80      0.76      0.77       214\n",
      "weighted avg       0.79      0.79      0.78       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# running with different regularization value since this is the main hyper parameter for SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(kernel=\"linear\", C=0.01)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_clf.predict(X_val)\n",
    "\n",
    "confusion_matrix(y_val, y_pred_svm)\n",
    "print(classification_report(y_val, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[115,  15],\n",
       "       [ 24,  60]], dtype=int64)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.83      0.88      0.86       130\n",
      "          MM       0.80      0.71      0.75        84\n",
      "\n",
      "    accuracy                           0.82       214\n",
      "   macro avg       0.81      0.80      0.80       214\n",
      "weighted avg       0.82      0.82      0.82       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(kernel=\"linear\", C=0.1)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_clf.predict(X_val)\n",
    "\n",
    "confusion_matrix(y_val, y_pred_svm)\n",
    "print(classification_report(y_val, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[116,  14],\n",
       "       [ 25,  59]], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.82      0.89      0.86       130\n",
      "          MM       0.81      0.70      0.75        84\n",
      "\n",
      "    accuracy                           0.82       214\n",
      "   macro avg       0.82      0.80      0.80       214\n",
      "weighted avg       0.82      0.82      0.82       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(kernel=\"linear\", C=1)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_clf.predict(X_val)\n",
    "\n",
    "confusion_matrix(y_val, y_pred_svm)\n",
    "print(classification_report(y_val, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=5, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[116,  14],\n",
       "       [ 27,  57]], dtype=int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.81      0.89      0.85       130\n",
      "          MM       0.80      0.68      0.74        84\n",
      "\n",
      "    accuracy                           0.81       214\n",
      "   macro avg       0.81      0.79      0.79       214\n",
      "weighted avg       0.81      0.81      0.80       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(kernel=\"linear\", C=5)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_clf.predict(X_val)\n",
    "\n",
    "confusion_matrix(y_val, y_pred_svm)\n",
    "print(classification_report(y_val, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=15, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[114,  16],\n",
       "       [ 25,  59]], dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.82      0.88      0.85       130\n",
      "          MM       0.79      0.70      0.74        84\n",
      "\n",
      "    accuracy                           0.81       214\n",
      "   macro avg       0.80      0.79      0.79       214\n",
      "weighted avg       0.81      0.81      0.81       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(kernel=\"linear\", C=15)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_clf.predict(X_val)\n",
    "\n",
    "confusion_matrix(y_val, y_pred_svm)\n",
    "print(classification_report(y_val, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[116,  14],\n",
       "       [ 25,  59]], dtype=int64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.82      0.89      0.86       130\n",
      "          MM       0.81      0.70      0.75        84\n",
      "\n",
      "    accuracy                           0.82       214\n",
      "   macro avg       0.82      0.80      0.80       214\n",
      "weighted avg       0.82      0.82      0.82       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model chosen after trying different values for the hyper parameter. I selected this based on accuracy and precision and recall\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(kernel=\"linear\", C=1)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_clf.predict(X_val)\n",
    "\n",
    "confusion_matrix(y_val, y_pred_svm)\n",
    "print(classification_report(y_val, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.05, loss='deviance', max_depth=1,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=0, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[116,  14],\n",
       "       [ 27,  57]], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.81      0.89      0.85       130\n",
      "          MM       0.80      0.68      0.74        84\n",
      "\n",
      "    accuracy                           0.81       214\n",
      "   macro avg       0.81      0.79      0.79       214\n",
      "weighted avg       0.81      0.81      0.80       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost has multiple hyper parameters\n",
    "# n_estimators controls the number of boosting stages\n",
    "# loss function and will leave that to default\n",
    "# learning_rate shrinks the contribution of each tree\n",
    "# max_depth limits the maximum depth of the trees\n",
    "# max_features which decideds how many features to use and whether we use sqrt or log or an interaction\n",
    "#random_State just uses a fixed seed\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf_gt = GradientBoostingClassifier(\n",
    "    n_estimators=100, learning_rate=0.05, max_depth=1, \n",
    "    random_state=0)\n",
    "clf_gt.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gt = clf_gt.predict(X_val)\n",
    "\n",
    "confusion_matrix(y_val, y_pred_gt)\n",
    "print(classification_report(y_val, y_pred_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.05, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=0, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[115,  15],\n",
       "       [ 27,  57]], dtype=int64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.81      0.88      0.85       130\n",
      "          MM       0.79      0.68      0.73        84\n",
      "\n",
      "    accuracy                           0.80       214\n",
      "   macro avg       0.80      0.78      0.79       214\n",
      "weighted avg       0.80      0.80      0.80       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# changing the values of the max_depth hyper parameter\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf_gt = GradientBoostingClassifier(\n",
    "    n_estimators=100, learning_rate=0.05, max_depth=3, \n",
    "    random_state=0)\n",
    "clf_gt.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gt = clf_gt.predict(X_val)\n",
    "\n",
    "confusion_matrix(y_val, y_pred_gt)\n",
    "print(classification_report(y_val, y_pred_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.05, loss='deviance', max_depth=5,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=0, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[109,  21],\n",
       "       [ 25,  59]], dtype=int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.81      0.84      0.83       130\n",
      "          MM       0.74      0.70      0.72        84\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.78      0.77      0.77       214\n",
      "weighted avg       0.78      0.79      0.78       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# changing the values of the max_depth hyper parameter\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf_gt = GradientBoostingClassifier(\n",
    "    n_estimators=100, learning_rate=0.05, max_depth=5, \n",
    "    random_state=0)\n",
    "clf_gt.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gt = clf_gt.predict(X_val)\n",
    "\n",
    "confusion_matrix(y_val, y_pred_gt)\n",
    "print(classification_report(y_val, y_pred_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.05, loss='deviance', max_depth=1,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=0, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[115,  15],\n",
       "       [ 27,  57]], dtype=int64)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.81      0.88      0.85       130\n",
      "          MM       0.79      0.68      0.73        84\n",
      "\n",
      "    accuracy                           0.80       214\n",
      "   macro avg       0.80      0.78      0.79       214\n",
      "weighted avg       0.80      0.80      0.80       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# changing the values of the n_estimators hyper parameter\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf_gt = GradientBoostingClassifier(\n",
    "    n_estimators=200, learning_rate=0.05, max_depth=1, \n",
    "    random_state=0)\n",
    "clf_gt.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gt = clf_gt.predict(X_val)\n",
    "\n",
    "confusion_matrix(y_val, y_pred_gt)\n",
    "print(classification_report(y_val, y_pred_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.05, loss='deviance', max_depth=1,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=50,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=0, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[115,  15],\n",
       "       [ 29,  55]], dtype=int64)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.80      0.88      0.84       130\n",
      "          MM       0.79      0.65      0.71        84\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.79      0.77      0.78       214\n",
      "weighted avg       0.79      0.79      0.79       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# changing the values of the n_estimators hyper parameter\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf_gt = GradientBoostingClassifier(\n",
    "    n_estimators=50, learning_rate=0.05, max_depth=1, \n",
    "    random_state=0)\n",
    "clf_gt.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gt = clf_gt.predict(X_val)\n",
    "\n",
    "confusion_matrix(y_val, y_pred_gt)\n",
    "print(classification_report(y_val, y_pred_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=1,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=0, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[116,  14],\n",
       "       [ 26,  58]], dtype=int64)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.82      0.89      0.85       130\n",
      "          MM       0.81      0.69      0.74        84\n",
      "\n",
      "    accuracy                           0.81       214\n",
      "   macro avg       0.81      0.79      0.80       214\n",
      "weighted avg       0.81      0.81      0.81       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# changing the values of the learning_rate hyper parameter\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf_gt = GradientBoostingClassifier(\n",
    "    n_estimators=100, learning_rate=0.1, max_depth=1, \n",
    "    random_state=0)\n",
    "clf_gt.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gt = clf_gt.predict(X_val)\n",
    "\n",
    "confusion_matrix(y_val, y_pred_gt)\n",
    "print(classification_report(y_val, y_pred_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.3, loss='deviance', max_depth=1,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=0, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[113,  17],\n",
       "       [ 27,  57]], dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.81      0.87      0.84       130\n",
      "          MM       0.77      0.68      0.72        84\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.79      0.77      0.78       214\n",
      "weighted avg       0.79      0.79      0.79       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# changing the values of the learning_rate hyper parameter\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf_gt = GradientBoostingClassifier(\n",
    "    n_estimators=100, learning_rate=0.3, max_depth=1, \n",
    "    random_state=0)\n",
    "clf_gt.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gt = clf_gt.predict(X_val)\n",
    "\n",
    "confusion_matrix(y_val, y_pred_gt)\n",
    "print(classification_report(y_val, y_pred_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=1,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=0, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[116,  14],\n",
       "       [ 26,  58]], dtype=int64)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CH       0.82      0.89      0.85       130\n",
      "          MM       0.81      0.69      0.74        84\n",
      "\n",
      "    accuracy                           0.81       214\n",
      "   macro avg       0.81      0.79      0.80       214\n",
      "weighted avg       0.81      0.81      0.81       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Chosen model after trying different hyper parameter values\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf_gt = GradientBoostingClassifier(\n",
    "    n_estimators=100, learning_rate=0.1, max_depth=1, \n",
    "    random_state=0)\n",
    "clf_gt.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gt = clf_gt.predict(X_val)\n",
    "\n",
    "confusion_matrix(y_val, y_pred_gt)\n",
    "print(classification_report(y_val, y_pred_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
